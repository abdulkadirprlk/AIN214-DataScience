{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIN 214 - PA1 - FALL 2023\n",
    "\n",
    "BELOW MD CELLS CONTAIN THE QUESTIONS YOU ARE ASKED TO IMPLEMENT WITHIN THE CONTEXT OF THIS HW. PLEASE FILL IN THE CELLS FOR THE ANSWERS RIGHT BELOW THE MD CELL OF THE QUESTION. YOU CAN ADD AS MANY CELLS AS YOU WANT, BE IT CODE OR MD, SO LONG AS YOU PROVIDE AN UNDERSTANDABLE AND TRACBLE REPORTING. PLEASE ADD COMMENTS ON YOUR CODES. ALSO, FILL IN MD CELLS WHERE YOU ARE ASKED YO COMMENT ON YOUR RESULTS OR EPXLAIN YOUR REASONING. ALSO, PLEASE DO NO HESITATE TO USE THEM FOR YOUR OWN REPORTING PURPOSES. PLEASE KEEP IN MIND THAT, REPORTING IS A KEY STEP IN DATA SCIENCE.\n",
    "\n",
    "Deadline: 03.11.2023 (23:59:59)\n",
    "\n",
    "Submission: Submit your Jupyter Notebooks via https://submit.cs.hacettepe.edu.tr/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T16:10:47.961084Z",
     "start_time": "2023-11-05T16:10:47.625754Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv#I imported this package in order to read the annots.csv file and create a sqlite3 db.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlite3 import connect\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "* Use pandas dataframe (df) to load the data. \n",
    "* Use numpy or pandas operations for the requested tasks unless otherwise specified. Use of naive for loops is not considered valid.\n",
    "* For the db operations, use sqlite3 library in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Set of Questions on Boston Housing Dataset **(30 Pts)**\n",
    "\n",
    "* Retrieved from KAGGLE\n",
    "* **Dataset Path: \"Data/BostonHousing.csv\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q1. Basic Data Exploration **(10 Pts)**\n",
    "1. Load the data into Pandas DataFrame and print the column names. **(1 pts)**\n",
    "2. Display the first and last 10 rows of the dataset. **(1 pts)**\n",
    "3. Display random 10 rows. **(1 pts)**\n",
    "4. Display random 10 rows with a seed, ie, it outputs the same random rows everytime it is run. **(1 pts)**\n",
    "5. Display every 15th row. **(1 pts)**\n",
    "6. Get the summary stats of the dataset regarding each column. **(2 pts)**\n",
    "7. Identify and count the number of missing values in each column. **(3 pts)**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into Pandas DataFrame and print the column names\n",
    "filePath = \"Data/BostonHousing.csv\"\n",
    "df = pd.read_csv(filePath)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first and last 10 rows of the dataset.\n",
    "df.head(10)#first 10 elements\n",
    "df.tail(10)#last 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the random 10 rows\n",
    "df.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample using seed\n",
    "df.sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display every 15th row\n",
    "df[::15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the summary stats of the dataset regarding each column\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and count the number of missing values in each column\n",
    "df.isna()#identifying each missing value\n",
    "df.isna().sum()#count of the missing values for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Data Filtering (10 pts)\n",
    "\n",
    "1. Extract records where the rm (average number of rooms per dwelling) >= 7.   **(2 pts)**\n",
    "2. Extract records located along the Charles River (chas = 1) and have a crime rate (crim) less than the median crime rate of the dataset.  **(2 pts)**\n",
    "3. Identify neighborhoods where the average rm is greater than 6, the lstat (% lower status of the population) is below 10, and the medv is above the 75th percentile of the dataset. This would give neighborhoods with relatively larger homes, lower \"lower-status\" population percentage, and higher median values.  **(2 pts)**\n",
    "4. Identify records where the dis (weighted distances to five Boston employment centers) is in the top 10% of the dataset and the nox (nitric oxides concentration) is in the bottom 10%, indicating neighborhoods that are farther from employment centers and have cleaner air.  **(2 pts)**\n",
    "5. From the houses built before 1940 (AGE column), select those which fall in the top 20% in terms of nitric oxide concentrations (NOX). From this subset, retrieve the bottom 10 records with the lowest MEDV values.  **(2 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract records where the rm >= 7\n",
    "df[df['rm'] >= 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract records located along the Charles River (chas = 1) and have a crime rate (crim) less than the median crime rate of the dataset.\n",
    "condition = (df['chas'] == 1) & (df['crim'] < df['crim'].median())\n",
    "df[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify neighborhoods where the average rm is greater than 6, the lstat (% lower status of the population) is below 10, and the medv is above \n",
    "# the 75th percentile of the dataset. \n",
    "condition = (df['rm'] > 6) & (df['lstat'] < 10) & (df['medv'] > df['medv'].quantile(0.75)) \n",
    "df[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify records where the dis (weighted distances to five Boston employment centers) is in the top 10% of the dataset and the nox \n",
    "# (nitric oxides concentration) is in the bottom 10%\n",
    "condition = (df['dis'] > df['dis'].quantile(0.90)) & (df['nox'] < df['nox'].quantile(0.10))\n",
    "df[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the houses built before 1940 (age column), select those which fall in the top 20% in terms of nitric oxide concentrations (nox). From this subset,\n",
    "# retrieve the bottom 10 records with the lowest medv values.\n",
    "condition = (df['age'] > 83) & (df['nox'] > df['nox'].quantile(0.80))#2023 - 1940 = 83/top 20% means above the 80% of the dataset\n",
    "df[condition].sort_values(by='medv').head(10)#sorted by ascending order and took the top 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Calculate the average per capita crime rate (crim) for each category, \"Low\", \"Medium\" or \"High\" of pupil-teacher ratio (ptratio). **(10 Pts)**\n",
    "The ptratio is categorized into\n",
    "* Low if ptratio <= 15\n",
    "* Medium if 15 < ptratio <= 20\n",
    "* High if ptratio > 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Calculate the average per capita crime rate (crim) for each category, \"Low\", \"Medium\" or \"High\" of pupil-teacher ratio (ptratio)\n",
    "#for Low category:\n",
    "condition = df['ptratio'] <= 15\n",
    "df[condition]['crim'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#for Medium category:\n",
    "condition = (df['ptratio'] <= 20) & (df['ptratio'] > 15)\n",
    "df[condition]['crim'].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#for High category:\n",
    "condition = df['ptratio'] > 20\n",
    "df[condition]['crim'].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Set of Questions on the shot1.csv and shot2.csv Datasets **(30 Pts)**\n",
    "\n",
    "* **Dataset Path: \"Data/shot1.csv\" and \"Data/shot2.csv\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Data Merging and Consistency Checking **(10 Pts)**\n",
    "\n",
    "* Combine the data from \"shot1.csv\" and \"shot2.csv\" into a single DataFrame, ensuring no redundant columns are present. Merge by the redundant column names, representing the same info with different naming.\n",
    "*  After merging, perform a consistency check for any duplicated rows and provide a summary of your findings. Give the details (avg, mean, etc) of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T16:11:05.040932Z",
     "start_time": "2023-11-05T16:11:04.890586Z"
    }
   },
   "outputs": [],
   "source": [
    "# read csv s into dfs \n",
    "df_shot1 = pd.read_csv(\"Data/shot1.csv\")\n",
    "df_shot2 = pd.read_csv(\"Data/shot2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T16:14:47.394967Z",
     "start_time": "2023-11-05T16:14:47.333384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    GAME_ID                     MATCHUP LOCATION  W  FINAL_MARGIN  \\\n0  21400899    MAR 04, 2015 - CHA @ BKN        A  W            24   \n1  21400899    MAR 04, 2015 - CHA @ BKN        A  W            24   \n2  21400899  MAR 04, 2015 - BKN vs. CHA        H  L           -24   \n3  21400899  MAR 04, 2015 - BKN vs. CHA        H  L           -24   \n4  21400899    MAR 04, 2015 - CHA @ BKN        A  W            24   \n5  21400899    MAR 04, 2015 - CHA @ BKN        A  W            24   \n6  21400899    MAR 04, 2015 - CHA @ BKN        A  W            24   \n7  21400899    MAR 04, 2015 - CHA @ BKN        A  W            24   \n8  21400899    MAR 04, 2015 - CHA @ BKN        A  W            24   \n9  21400899    MAR 04, 2015 - CHA @ BKN        A  W            24   \n\n   SHOT_NUMBER  PERIOD GAME_CLOCK  SHOT_CLOCK  DRIBBLES  ...  SHOT_DIST  \\\n0            1       1       1:09        10.8         2  ...        7.7   \n1            1       1       1:09        10.8         2  ...        7.7   \n2            5       2      11:06        14.7         5  ...        7.7   \n3            5       2      11:06        14.7         5  ...        7.7   \n4            2       1       0:14         3.4         0  ...       28.2   \n5            3       1       0:00         NaN         3  ...       10.1   \n6            4       2      11:47        10.3         2  ...       17.2   \n7            4       2      11:47        10.3         2  ...       17.2   \n8            2       4      10:58        15.3         4  ...       17.2   \n9            2       4      10:58        15.3         4  ...       17.2   \n\n   SHOT_RESULT PTS_TYPE   CLOSEST_DEFENDER CLOSEST_DEFENDER_PLAYER_ID  \\\n0         made        2     Anderson, Alan                     101187   \n1         made        2     Roberts, Brian                     203148   \n2         made        2     Anderson, Alan                     101187   \n3         made        2     Roberts, Brian                     203148   \n4       missed        3  Bogdanovic, Bojan                     202711   \n5       missed        2  Bogdanovic, Bojan                     202711   \n6       missed        2      Brown, Markel                     203900   \n7       missed        2      Brown, Markel                     203900   \n8       missed        2      Brown, Markel                     203900   \n9       missed        2      Brown, Markel                     203900   \n\n   CLOSE_DEF_DIST  FGM  PTS       player_name player_id  \n0             1.3    1    2     brian roberts    203148  \n1             2.9    1    2      jarrett jack    101127  \n2             1.3    1    2     brian roberts    203148  \n3             2.9    1    2      jarrett jack    101127  \n4             6.1    0    0     brian roberts    203148  \n5             0.9    0    0     brian roberts    203148  \n6             3.4    0    0     brian roberts    203148  \n7             3.9    0    0  lance stephenson    202362  \n8             3.4    0    0     brian roberts    203148  \n9             3.9    0    0  lance stephenson    202362  \n\n[10 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GAME_ID</th>\n      <th>MATCHUP</th>\n      <th>LOCATION</th>\n      <th>W</th>\n      <th>FINAL_MARGIN</th>\n      <th>SHOT_NUMBER</th>\n      <th>PERIOD</th>\n      <th>GAME_CLOCK</th>\n      <th>SHOT_CLOCK</th>\n      <th>DRIBBLES</th>\n      <th>...</th>\n      <th>SHOT_DIST</th>\n      <th>SHOT_RESULT</th>\n      <th>PTS_TYPE</th>\n      <th>CLOSEST_DEFENDER</th>\n      <th>CLOSEST_DEFENDER_PLAYER_ID</th>\n      <th>CLOSE_DEF_DIST</th>\n      <th>FGM</th>\n      <th>PTS</th>\n      <th>player_name</th>\n      <th>player_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21400899</td>\n      <td>MAR 04, 2015 - CHA @ BKN</td>\n      <td>A</td>\n      <td>W</td>\n      <td>24</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1:09</td>\n      <td>10.8</td>\n      <td>2</td>\n      <td>...</td>\n      <td>7.7</td>\n      <td>made</td>\n      <td>2</td>\n      <td>Anderson, Alan</td>\n      <td>101187</td>\n      <td>1.3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>brian roberts</td>\n      <td>203148</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21400899</td>\n      <td>MAR 04, 2015 - CHA @ BKN</td>\n      <td>A</td>\n      <td>W</td>\n      <td>24</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1:09</td>\n      <td>10.8</td>\n      <td>2</td>\n      <td>...</td>\n      <td>7.7</td>\n      <td>made</td>\n      <td>2</td>\n      <td>Roberts, Brian</td>\n      <td>203148</td>\n      <td>2.9</td>\n      <td>1</td>\n      <td>2</td>\n      <td>jarrett jack</td>\n      <td>101127</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21400899</td>\n      <td>MAR 04, 2015 - BKN vs. CHA</td>\n      <td>H</td>\n      <td>L</td>\n      <td>-24</td>\n      <td>5</td>\n      <td>2</td>\n      <td>11:06</td>\n      <td>14.7</td>\n      <td>5</td>\n      <td>...</td>\n      <td>7.7</td>\n      <td>made</td>\n      <td>2</td>\n      <td>Anderson, Alan</td>\n      <td>101187</td>\n      <td>1.3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>brian roberts</td>\n      <td>203148</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21400899</td>\n      <td>MAR 04, 2015 - BKN vs. CHA</td>\n      <td>H</td>\n      <td>L</td>\n      <td>-24</td>\n      <td>5</td>\n      <td>2</td>\n      <td>11:06</td>\n      <td>14.7</td>\n      <td>5</td>\n      <td>...</td>\n      <td>7.7</td>\n      <td>made</td>\n      <td>2</td>\n      <td>Roberts, Brian</td>\n      <td>203148</td>\n      <td>2.9</td>\n      <td>1</td>\n      <td>2</td>\n      <td>jarrett jack</td>\n      <td>101127</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21400899</td>\n      <td>MAR 04, 2015 - CHA @ BKN</td>\n      <td>A</td>\n      <td>W</td>\n      <td>24</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0:14</td>\n      <td>3.4</td>\n      <td>0</td>\n      <td>...</td>\n      <td>28.2</td>\n      <td>missed</td>\n      <td>3</td>\n      <td>Bogdanovic, Bojan</td>\n      <td>202711</td>\n      <td>6.1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>brian roberts</td>\n      <td>203148</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>21400899</td>\n      <td>MAR 04, 2015 - CHA @ BKN</td>\n      <td>A</td>\n      <td>W</td>\n      <td>24</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0:00</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>...</td>\n      <td>10.1</td>\n      <td>missed</td>\n      <td>2</td>\n      <td>Bogdanovic, Bojan</td>\n      <td>202711</td>\n      <td>0.9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>brian roberts</td>\n      <td>203148</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>21400899</td>\n      <td>MAR 04, 2015 - CHA @ BKN</td>\n      <td>A</td>\n      <td>W</td>\n      <td>24</td>\n      <td>4</td>\n      <td>2</td>\n      <td>11:47</td>\n      <td>10.3</td>\n      <td>2</td>\n      <td>...</td>\n      <td>17.2</td>\n      <td>missed</td>\n      <td>2</td>\n      <td>Brown, Markel</td>\n      <td>203900</td>\n      <td>3.4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>brian roberts</td>\n      <td>203148</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>21400899</td>\n      <td>MAR 04, 2015 - CHA @ BKN</td>\n      <td>A</td>\n      <td>W</td>\n      <td>24</td>\n      <td>4</td>\n      <td>2</td>\n      <td>11:47</td>\n      <td>10.3</td>\n      <td>2</td>\n      <td>...</td>\n      <td>17.2</td>\n      <td>missed</td>\n      <td>2</td>\n      <td>Brown, Markel</td>\n      <td>203900</td>\n      <td>3.9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>lance stephenson</td>\n      <td>202362</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>21400899</td>\n      <td>MAR 04, 2015 - CHA @ BKN</td>\n      <td>A</td>\n      <td>W</td>\n      <td>24</td>\n      <td>2</td>\n      <td>4</td>\n      <td>10:58</td>\n      <td>15.3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>17.2</td>\n      <td>missed</td>\n      <td>2</td>\n      <td>Brown, Markel</td>\n      <td>203900</td>\n      <td>3.4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>brian roberts</td>\n      <td>203148</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>21400899</td>\n      <td>MAR 04, 2015 - CHA @ BKN</td>\n      <td>A</td>\n      <td>W</td>\n      <td>24</td>\n      <td>2</td>\n      <td>4</td>\n      <td>10:58</td>\n      <td>15.3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>17.2</td>\n      <td>missed</td>\n      <td>2</td>\n      <td>Brown, Markel</td>\n      <td>203900</td>\n      <td>3.9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>lance stephenson</td>\n      <td>202362</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge dfs, removing redundant columns\n",
    "merged_df = pd.merge(df_shot1, df_shot2, left_on=['GAME_ID', 'SHOT_RESULT', 'SHOT_DIST'],\n",
    "                      right_on=['GAME_IDENTIFICATION', 'SHOT_RESULT', 'SHOT_DIST'], how='inner')\n",
    "merged_df.drop('GAME_IDENTIFICATION', axis=1, inplace=True)\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate rows and provide a summary of the findings for each feature\n",
    "merged_df[merged_df.duplicated()].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "    GAME_ID                     MATCHUP LOCATION  W  FINAL_MARGIN  \\\n0  21400001  OCT 28, 2014 - NOP vs. ORL        H  W            17   \n1  21400001  OCT 28, 2014 - NOP vs. ORL        H  W            17   \n2  21400001  OCT 28, 2014 - NOP vs. ORL        H  W            17   \n3  21400001  OCT 28, 2014 - NOP vs. ORL        H  W            17   \n4  21400001  OCT 28, 2014 - NOP vs. ORL        H  W            17   \n5  21400001  OCT 28, 2014 - NOP vs. ORL        H  W            17   \n6  21400001  OCT 28, 2014 - NOP vs. ORL        H  W            17   \n7  21400001  OCT 28, 2014 - NOP vs. ORL        H  W            17   \n8  21400001  OCT 28, 2014 - NOP vs. ORL        H  W            17   \n9  21400001  OCT 28, 2014 - NOP vs. ORL        H  W            17   \n\n   SHOT_NUMBER  PERIOD GAME_CLOCK  SHOT_CLOCK  DRIBBLES  ...  SHOT_DIST_y  \\\n0           15       3      10:38        24.0         0  ...          2.2   \n1           15       3      10:38        24.0         0  ...          3.1   \n2           15       3      10:38        24.0         0  ...          4.7   \n3           15       3      10:38        24.0         0  ...          7.4   \n4           15       3      10:38        24.0         0  ...         16.4   \n5           15       3      10:38        24.0         0  ...          4.6   \n6           15       3      10:38        24.0         0  ...          2.5   \n7           15       3      10:38        24.0         0  ...          5.1   \n8           15       3      10:38        24.0         0  ...         18.9   \n9           15       3      10:38        24.0         0  ...          0.6   \n\n   PTS_TYPE SHOT_RESULT_y  CLOSEST_DEFENDER  CLOSEST_DEFENDER_PLAYER_ID  \\\n0         2          made    Harris, Tobias                      202699   \n1         2          made     O'Quinn, Kyle                      203124   \n2         2        missed     O'Quinn, Kyle                      203124   \n3         2        missed     O'Quinn, Kyle                      203124   \n4         2          made   Vucevic, Nikola                      202696   \n5         2          made     O'Quinn, Kyle                      203124   \n6         2        missed        Asik, Omer                      201600   \n7         2        missed        Asik, Omer                      201600   \n8         2        missed        Asik, Omer                      201600   \n9         2          made    Davis, Anthony                      203076   \n\n  CLOSE_DEF_DIST FGM  PTS     player_name  player_id  \n0            1.7   1    2   anthony davis     203076  \n1            3.4   1    2   anthony davis     203076  \n2            1.4   0    0   anthony davis     203076  \n3            2.7   0    0   anthony davis     203076  \n4            6.3   1    2   anthony davis     203076  \n5            7.7   1    2   anthony davis     203076  \n6            2.4   0    0  nikola vucevic     202696  \n7            1.7   0    0  nikola vucevic     202696  \n8            5.5   0    0  nikola vucevic     202696  \n9            2.0   1    2  nikola vucevic     202696  \n\n[10 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GAME_ID</th>\n      <th>MATCHUP</th>\n      <th>LOCATION</th>\n      <th>W</th>\n      <th>FINAL_MARGIN</th>\n      <th>SHOT_NUMBER</th>\n      <th>PERIOD</th>\n      <th>GAME_CLOCK</th>\n      <th>SHOT_CLOCK</th>\n      <th>DRIBBLES</th>\n      <th>...</th>\n      <th>SHOT_DIST_y</th>\n      <th>PTS_TYPE</th>\n      <th>SHOT_RESULT_y</th>\n      <th>CLOSEST_DEFENDER</th>\n      <th>CLOSEST_DEFENDER_PLAYER_ID</th>\n      <th>CLOSE_DEF_DIST</th>\n      <th>FGM</th>\n      <th>PTS</th>\n      <th>player_name</th>\n      <th>player_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21400001</td>\n      <td>OCT 28, 2014 - NOP vs. ORL</td>\n      <td>H</td>\n      <td>W</td>\n      <td>17</td>\n      <td>15</td>\n      <td>3</td>\n      <td>10:38</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2.2</td>\n      <td>2</td>\n      <td>made</td>\n      <td>Harris, Tobias</td>\n      <td>202699</td>\n      <td>1.7</td>\n      <td>1</td>\n      <td>2</td>\n      <td>anthony davis</td>\n      <td>203076</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21400001</td>\n      <td>OCT 28, 2014 - NOP vs. ORL</td>\n      <td>H</td>\n      <td>W</td>\n      <td>17</td>\n      <td>15</td>\n      <td>3</td>\n      <td>10:38</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3.1</td>\n      <td>2</td>\n      <td>made</td>\n      <td>O'Quinn, Kyle</td>\n      <td>203124</td>\n      <td>3.4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>anthony davis</td>\n      <td>203076</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21400001</td>\n      <td>OCT 28, 2014 - NOP vs. ORL</td>\n      <td>H</td>\n      <td>W</td>\n      <td>17</td>\n      <td>15</td>\n      <td>3</td>\n      <td>10:38</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4.7</td>\n      <td>2</td>\n      <td>missed</td>\n      <td>O'Quinn, Kyle</td>\n      <td>203124</td>\n      <td>1.4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>anthony davis</td>\n      <td>203076</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21400001</td>\n      <td>OCT 28, 2014 - NOP vs. ORL</td>\n      <td>H</td>\n      <td>W</td>\n      <td>17</td>\n      <td>15</td>\n      <td>3</td>\n      <td>10:38</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>7.4</td>\n      <td>2</td>\n      <td>missed</td>\n      <td>O'Quinn, Kyle</td>\n      <td>203124</td>\n      <td>2.7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>anthony davis</td>\n      <td>203076</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21400001</td>\n      <td>OCT 28, 2014 - NOP vs. ORL</td>\n      <td>H</td>\n      <td>W</td>\n      <td>17</td>\n      <td>15</td>\n      <td>3</td>\n      <td>10:38</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>16.4</td>\n      <td>2</td>\n      <td>made</td>\n      <td>Vucevic, Nikola</td>\n      <td>202696</td>\n      <td>6.3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>anthony davis</td>\n      <td>203076</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>21400001</td>\n      <td>OCT 28, 2014 - NOP vs. ORL</td>\n      <td>H</td>\n      <td>W</td>\n      <td>17</td>\n      <td>15</td>\n      <td>3</td>\n      <td>10:38</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4.6</td>\n      <td>2</td>\n      <td>made</td>\n      <td>O'Quinn, Kyle</td>\n      <td>203124</td>\n      <td>7.7</td>\n      <td>1</td>\n      <td>2</td>\n      <td>anthony davis</td>\n      <td>203076</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>21400001</td>\n      <td>OCT 28, 2014 - NOP vs. ORL</td>\n      <td>H</td>\n      <td>W</td>\n      <td>17</td>\n      <td>15</td>\n      <td>3</td>\n      <td>10:38</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2.5</td>\n      <td>2</td>\n      <td>missed</td>\n      <td>Asik, Omer</td>\n      <td>201600</td>\n      <td>2.4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>nikola vucevic</td>\n      <td>202696</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>21400001</td>\n      <td>OCT 28, 2014 - NOP vs. ORL</td>\n      <td>H</td>\n      <td>W</td>\n      <td>17</td>\n      <td>15</td>\n      <td>3</td>\n      <td>10:38</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>5.1</td>\n      <td>2</td>\n      <td>missed</td>\n      <td>Asik, Omer</td>\n      <td>201600</td>\n      <td>1.7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>nikola vucevic</td>\n      <td>202696</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>21400001</td>\n      <td>OCT 28, 2014 - NOP vs. ORL</td>\n      <td>H</td>\n      <td>W</td>\n      <td>17</td>\n      <td>15</td>\n      <td>3</td>\n      <td>10:38</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>18.9</td>\n      <td>2</td>\n      <td>missed</td>\n      <td>Asik, Omer</td>\n      <td>201600</td>\n      <td>5.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>nikola vucevic</td>\n      <td>202696</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>21400001</td>\n      <td>OCT 28, 2014 - NOP vs. ORL</td>\n      <td>H</td>\n      <td>W</td>\n      <td>17</td>\n      <td>15</td>\n      <td>3</td>\n      <td>10:38</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>made</td>\n      <td>Davis, Anthony</td>\n      <td>203076</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>nikola vucevic</td>\n      <td>202696</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 23 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# merge dfs, removing redundant columns\n",
    "\n",
    "df1 = pd.read_csv('Data/shot1.csv')\n",
    "df2 = pd.read_csv('Data/shot2.csv')\n",
    "\n",
    "key1 = df1['GAME_ID'].values\n",
    "key2 = df2['GAME_IDENTIFICATION'].values\n",
    "\n",
    "sorted_ind1 = np.argsort(key1)\n",
    "sorted_ind2 = np.argsort(key2)\n",
    "\n",
    "sorted_df1 = df1.iloc[sorted_ind1]\n",
    "sorted_df2 = df2.iloc[sorted_ind2]\n",
    "\n",
    "df = pd.merge(sorted_df1, sorted_df2, left_on='GAME_ID', right_on='GAME_IDENTIFICATION')\n",
    "\n",
    "# Remove the redundant columns\n",
    "df = df.drop(['GAME_IDENTIFICATION'], axis=1)\n",
    "\n",
    "display(df.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:14:14.146683Z",
     "start_time": "2023-11-05T16:14:08.838092Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Player’s Shooting Accuracy Analysis **(10 Pts)**\n",
    "* Using the combined DataFrame from Question 1, calculate and display the shooting accuracy of each player. \n",
    "* Shooting accuracy = the ratio of successful shots (SHOT_RESULT) to total shots taken\n",
    "* Display the top 5 players based on shooting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shooting accuracy of each player\n",
    "grouped_data = merged_df.groupby('player_name')\n",
    "total_shots = grouped_data['SHOT_RESULT'].count()        \n",
    "made_shots = grouped_data['SHOT_RESULT'].apply(lambda x: (x == 'made').sum())\n",
    "shot_accuracy = round(((made_shots / total_shots)*100),2)\n",
    "result_df = pd.DataFrame({'player_name': total_shots.index, 'shot_accuracy_percentage': shot_accuracy}).reset_index(drop=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Analyze the Relationship between shooting distance (SHOT_DIST) and shooting success (SHOT_RESULT). **(10 Pts)**\n",
    "* Bin the shots into categories based on distance. **STATE AND REASON ABOUT YOUR LOGIC HERE!** (How to apply binning)\n",
    "* Calculate the shooting accuracy for each bin. \n",
    "* **COMMENT** on your findinds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shot data categorized based on the distance(SHOT_DIST)\n",
    "#long_shot > 20, 20 >= intermediate_shot > 10, close_shot <= 10\n",
    "condition1 = merged_df['SHOT_DIST'] > 20\n",
    "condition2 = (merged_df['SHOT_DIST'] <= 20) & (merged_df['SHOT_DIST'] > 10)\n",
    "condition3 = merged_df['SHOT_DIST'] <= 10\n",
    "merged_df['SHOT_CATEGORY'] = np.where(condition1, 'long_shot', np.where(condition2, 'medium_shot', 'close_shot'))\n",
    "grouped = merged_df.groupby('SHOT_CATEGORY')\n",
    "total_shots = grouped['SHOT_RESULT'].count()\n",
    "made_shots = grouped['SHOT_RESULT'].apply(lambda x: (x == 'made').sum())\n",
    "shot_accuracy = round(((made_shots / total_shots)*100),2)\n",
    "result_df = pd.DataFrame({'shot_category': total_shots.index, 'shot_accuracy_percentage': shot_accuracy}).reset_index(drop=True)\n",
    "result_df\n",
    "#The shots are binned into categories and found the shot_accuracy's of each category. We can say that the shots taken closely are more likely\n",
    "#to score and the shots taken by the long distance have the least accuracy percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd Set of Questions on SQL - **using sqlite3 library!** **(40 Pts)**\n",
    "\n",
    "* **Dataset Path: \"Data/annots.csv\"**\n",
    "\n",
    "Here you are given a file: annots.csv, with the protein - gene ontology (GO) term associations/annotations. Gene ontology is a framework, representing the properties of genes and proteins. This is basically a Graph - more spesifically a directed acyclic graph (DAG), representing a level-ordered hierarchy with three subgraphs: MF, CC, and BP. Here, **each** node in the graph, which we term as **\"GO Term\" corresponds to a function of a protein.**\n",
    "\n",
    "* If protein is annotated with a GO Term, then the protein has the function represented by this GO Term. \n",
    "* A protein can be and most of the time is annotated with multiple GO terms, and vice versa. \n",
    "\n",
    "In the annots.csv file, we have the annotation data, where each row corresponds to a protein - GO term annotation with the following columns: ProteinID,ProtSeq, GO_ID, Sub_Graph, Level. ProteinID is the specifier of the protein and the ProtSeq is the aminoacid sequence of this protein. GO_ID, Sub_Graph, and Level are properties of a GO Term. \n",
    "\n",
    "**Now, we want to store this data in a relational database, with the following table schemas:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1: GoTerms:\n",
    "\n",
    "| Column   | Type    | Key        | Description                |\n",
    "|----------|---------|------------|----------------------------|\n",
    "| GoID     | TEXT    | PRIMARY KEY| Gene Ontology Identifier   |\n",
    "| SubGraph | TEXT    |            | Subgraph Type (BP, MF, CC) |\n",
    "| Level    | INTEGER |            | Ontology level             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2: Proteins\n",
    "\n",
    "| Column     | Type | Key        | Description                |\n",
    "|------------|------|------------|----------------------------|\n",
    "| ProteinID  | TEXT | PRIMARY KEY| Unique Protein Identifier  |\n",
    "| ProtSeq  | TEXT | | Amino Acid Sequence |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 3: Annotations\n",
    "\n",
    "| Column    | Type | Key                       | Description               |\n",
    "|-----------|------|---------------------------|---------------------------|\n",
    "| GoID      | TEXT | PRIMARY KEY, FOREIGN KEY  | Gene Ontology Identifier  |\n",
    "| ProteinID | TEXT | PRIMARY KEY, FOREIGN KEY  | Unique Protein Identifier |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Read the csv file and create this DB  **(10 Pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T20:24:55.897881Z",
     "start_time": "2023-11-03T20:24:55.807601Z"
    }
   },
   "outputs": [],
   "source": [
    "# read file into db and create a db using sqlite3\n",
    "datasetPath = \"Data/annots.csv\"\n",
    "conn = sqlite3.connect(\"annots.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create tables\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS GoTerms (\n",
    "        GoID TEXT PRIMARY KEY,\n",
    "        SubGraph TEXT,\n",
    "        Level INTEGER\n",
    "    )\n",
    "''')\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Proteins (\n",
    "        ProteinID TEXT PRIMARY KEY,\n",
    "        ProtSeq TEXT\n",
    "    )\n",
    "''')\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Annotations (\n",
    "        GoID TEXT,\n",
    "        ProteinID TEXT,\n",
    "        PRIMARY KEY (GoID, ProteinID),\n",
    "        FOREIGN KEY (GoID) REFERENCES GoTerms(GoID),\n",
    "        FOREIGN KEY (ProteinID) REFERENCES Proteins(ProteinID)\n",
    "    )\n",
    "''')\n",
    "conn.commit()\n",
    "# Import data from the CSV file\n",
    "try:\n",
    "    with open(datasetPath, \"r\") as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for row in csv_reader:\n",
    "            cursor.execute(\"INSERT OR IGNORE INTO GoTerms (GoID, SubGraph, Level) VALUES (?, ?, ?)\", (row[2], row[3], row[4]))\n",
    "            cursor.execute(\"INSERT OR IGNORE INTO Proteins (ProteinID, ProtSeq) VALUES (?, ?)\", (row[0], row[1]))\n",
    "            cursor.execute(\"INSERT OR IGNORE INTO Annotations (GoID, ProteinID) VALUES (?, ?)\", (row[2], row[0]))\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Define a function to extract all GO terms associated with a given amino acid sequence (ProtSeq), ensuring that the GO terms satisfy the following criteria: they are annotated with at least 50 proteins in MF and CC subgraphs, and 100 proteins in the BP subgraph.. **(10 Pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T20:03:06.006453Z",
     "start_time": "2023-10-30T20:03:05.981109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot_seq = \"VDDIQEKMNKELGCIKVTFPGADGQGEDACLKDIPVSLISTYFARTAWTDIIRV\" #  example protein sequence\n",
    "#I actually couldn't find any prot_seq that satisfies the conditions you gave or maybe I misunderstood the question, it is probably the case :( \n",
    "\n",
    "# function to extract the annotated GO terms with the above specs\n",
    "def extract_go_terms(prot_seq):\n",
    "    conn = sqlite3.connect(\"annots.db\")\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    results = []\n",
    "    MF_count = 0#MF sub graph count should be at least 50\n",
    "    CC_count = 0#CC sub graph count should be at least 50\n",
    "    BP_count = 0#BP sub graph count should be at least 100\n",
    "    \n",
    "    try:\n",
    "        cursor.execute('''\n",
    "                SELECT G.GoID, G.SubGraph\n",
    "                FROM GoTerms G, Annotations A, Proteins P\n",
    "                WHERE G.GoID = A.GoID AND A.ProteinID = P.ProteinID\n",
    "                AND P.ProtSeq = ?\n",
    "                GROUP BY G.GoID\n",
    "                HAVING (G.SubGraph = 'MF' OR G.SubGraph = 'CC') AND COUNT(DISTINCT P.ProteinID) >= 50\n",
    "            OR (G.SubGraph = 'BP') AND COUNT(DISTINCT P.ProteinID) >= 100\n",
    "        ''', (prot_seq,))\n",
    "        \n",
    "        go_terms = cursor.fetchall()\n",
    "        results = [row[0] for row in go_terms]\n",
    "        \n",
    "        #this is a solution with for loop but it doesn't support the usage of group by and having keyword\n",
    "        '''for go_id, sub_graph in go_terms:\n",
    "            if(sub_graph == \"MF\"):\n",
    "                MF_count += 1\n",
    "            elif(sub_graph == \"CC\"):\n",
    "                CC_count += 1\n",
    "            elif(sub_graph == \"BP\"):\n",
    "                BP_count += 1\n",
    "        \n",
    "        for go_id, sub_graph in go_terms:\n",
    "            if(sub_graph == \"MF\" and MF_count >= 50) or (sub_graph == \"CC\" and CC_count >= 50) or (sub_graph == \"BP\" and BP_count >= 100):\n",
    "                results.append(go_id)'''\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "        \n",
    "    return results\n",
    "\n",
    "extract_go_terms(prot_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Print the average number of annotations a GO terms has for each level in each subgraph (MF, CC, and BP) **(10 Pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T19:21:35.460769Z",
     "start_time": "2023-11-03T19:21:35.450563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: no such column: SubGraph\n"
     ]
    }
   ],
   "source": [
    "# Print the avg # of annots\n",
    "conn = sqlite3.connect(\"annots.db\")\n",
    "cursor = conn.cursor()\n",
    "try:\n",
    "    cursor.execute('''\n",
    "    SELECT G.Level, G.GoID, avg(count(distinct G.GoID)) \n",
    "    FROM Annotations A, GoTerms G\n",
    "    WHERE A.GoID = G.GoID\n",
    "    GROUP BY G.Level\n",
    "    \n",
    "    ''')\n",
    "    \n",
    "    print(cursor.fetchall())\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "finally:\n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Identify the ProteinID with the longest ProtSeq within the Proteins table. Modify its ProtSeq to half its original length by trimming the sequence, update the ProteinID to \"trimmed\", and display the updated ProteinID and ProtSeq with its GO Term annotations. **(10 Pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T20:25:11.219614Z",
     "start_time": "2023-11-03T20:25:11.018264Z"
    }
   },
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "UNIQUE constraint failed: Proteins.ProteinID",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIntegrityError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 21\u001B[0m\n\u001B[1;32m     19\u001B[0m new_protein_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrimmed\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Insert the new row with the trimmed protein and the new ProteinID\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m cursor\u001B[38;5;241m.\u001B[39mexecute(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINSERT INTO Proteins (ProteinID, ProtSeq) VALUES (?, ?)\u001B[39m\u001B[38;5;124m\"\u001B[39m, (new_protein_id, trimmed_protseq))\n\u001B[1;32m     22\u001B[0m conn\u001B[38;5;241m.\u001B[39mcommit()\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# Step 4: Copy the GO Term annotations from the old row to the new row\u001B[39;00m\n",
      "\u001B[0;31mIntegrityError\u001B[0m: UNIQUE constraint failed: Proteins.ProteinID"
     ]
    }
   ],
   "source": [
    "# find and trim the longest sequence, displaying the updated ProtID and ProtSeq, and its annotated GO Terms\n",
    "conn = sqlite3.connect(\"annots.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#ordering the protseqs by length\n",
    "cursor.execute('''\n",
    "            SELECT ProteinID, ProtSeq \n",
    "            FROM Proteins \n",
    "            ORDER BY LENGTH(ProtSeq) DESC LIMIT 1''')\n",
    "\n",
    "result = cursor.fetchone()\n",
    "id_of_the_longest_protein = result[0]\n",
    "the_longest_protseq = result[1]\n",
    "\n",
    "# trimming the protseq\n",
    "half_length = len(the_longest_protseq) // 2\n",
    "trimmed_protseq = the_longest_protseq[:half_length]\n",
    "\n",
    "new_protein_id = \"trimmed\"\n",
    "# Insert the new row with the trimmed protein and the new ProteinID\n",
    "cursor.execute(\"INSERT INTO Proteins (ProteinID, ProtSeq) VALUES (?, ?)\", (new_protein_id, trimmed_protseq))\n",
    "conn.commit()\n",
    "\n",
    "#Copy the GO Term annotations from the old row to the new row\n",
    "cursor.execute(\"INSERT INTO Annotations (GoID, ProteinID) SELECT GoID, ? FROM Annotations WHERE ProteinID = ?\", (new_protein_id, id_of_the_longest_protein))\n",
    "conn.commit()\n",
    "\n",
    "#Delete the old row\n",
    "cursor.execute(\"DELETE FROM Proteins WHERE ProteinID = ?\", (id_of_the_longest_protein,))\n",
    "conn.commit()\n",
    "\n",
    "#since ProteinID is a primary key in this database, I wanted to add another column with the specified values and delete the row has the \n",
    "#trimmed ProtSeq (the old record) , but it didn't seem to work properly :(\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "SELECT p.ProteinID, p.ProtSeq, a.GoID\n",
    "FROM Proteins p, Annotations a\n",
    "WHERE p.ProteinID = a.ProteinID\n",
    "AND p.ProteinID = \"trimmed\"\n",
    "\"\"\")\n",
    "result = cursor.fetchall()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLAGIARISM\n",
    "All work on assignments must be done individually. You are encouraged to discuss\n",
    "the given assignments with your classmates, but these discussions should be carried out\n",
    "in an abstract way. That is, discussions related to a particular solution to a specific prob-\n",
    "lem (either in actual code or in pseudocode) will not be tolerated. In short, turning\n",
    "in someone else’s work (including work available on the internet), in whole or in part, as\n",
    "your own will be considered as a violation of academic integrity. Please note that the\n",
    "former conditions also hold for the material attained using AI tools, including ChatGPT,\n",
    "GitHub Copilot, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
